{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abdullah12389/Multimart/blob/main/vernelable_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjGhgX4LOnad"
      },
      "outputs": [],
      "source": [
        "import requests as re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM-EYaS8OrSc",
        "outputId": "b905777b-b3c7-4238-8aa8-c717343427af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "20it [00:00, 41.48it/s]\n"
          ]
        }
      ],
      "source": [
        "data=pd.DataFrame()\n",
        "for chunk in tqdm(pd.read_csv(\"/content/myntra202305041052.csv\",chunksize=1000,on_bad_lines='skip',nrows=20000)):\n",
        "  data=pd.concat([data,chunk])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u4q4grPPFMp"
      },
      "outputs": [],
      "source": [
        "data=data.sample(2000)\n",
        "data=data.loc[:,'name':\"img\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXdzDjIMToKl"
      },
      "outputs": [],
      "source": [
        "data=data.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBWd4VZBRdNr"
      },
      "outputs": [],
      "source": [
        "words=np.array([])\n",
        "for word in data[\"name\"]:\n",
        "  word=word.split()\n",
        "  words=np.append(words,word[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qauVKEDtT3Qb"
      },
      "outputs": [],
      "source": [
        "dat=pd.concat([data.drop(columns=[\"name\"]),pd.DataFrame(words,columns=[\"label\"])],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lq5BiYOUVdKs"
      },
      "outputs": [],
      "source": [
        "for i,word in enumerate(dat[\"label\"]):\n",
        "  if word.isdigit():\n",
        "    dat.drop(index=i,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "YF_uFTORV_5t",
        "outputId": "be2f0e35-18c6-4800-b5cb-e56658a67a65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt</th>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Set</th>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jeans</th>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Watch</th>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Backpack</th>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ml</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>suit</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Saree</th>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trousers</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Covers</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Top</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shorts</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "label\n",
              "T-shirt     139\n",
              "Set         105\n",
              "Jeans        63\n",
              "Watch        61\n",
              "Backpack     59\n",
              "Dress        56\n",
              "ml           48\n",
              "suit         40\n",
              "Saree        39\n",
              "Trousers     38\n",
              "Covers       36\n",
              "Top          33\n",
              "Shorts       33\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "condition=dat[\"label\"].value_counts()>30\n",
        "dat[\"label\"].value_counts()[condition]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JixQmLrEWxUn",
        "outputId": "45934d5f-0901-42ff-ff44-cb85f9685676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Strobe Dewy Skin Tint 30 ml\n",
            "Cream Skin Refiner 150 ml\n",
            "Stretch Mark Oil 200 ml\n",
            "Bronze Body Perfume 120 ml\n",
            "Men Oud Extreme EDP - 100 ml\n",
            "Tranquil Body Wash 470 ml\n",
            "Green Tea Daylight Sustainable Sunscreen Gel 50 ml\n",
            "SPF 15 Body Lotion 200 ml\n",
            "Baby Daily Lotion - 400 ml\n",
            "Makeup Setting Spray - 60 ml\n",
            "Aloe Vera Gel 300 ml\n",
            "Unisex Sustainable Face Lotion 50 ml\n",
            "Men Dream Big EDT 100 ml\n",
            "Revitalift Night Cream 50 ml\n",
            "Handy 850 Water Bottle 780 ml\n",
            "Sustain Pure Rose Water 200 ml\n",
            "Men Intimately 150 ml\n",
            "Retinol Night Cream - 60 ml\n",
            "Men Deep Impact Roll-On 50 ml\n",
            "Men Silver Scent EDT 100 ml\n",
            "Nayaab Eau De Parfum - 100 ml\n",
            "Men Xpressio EDP 100 ml\n",
            "Women Eau de Toilette 30 ml\n",
            "Eladi Hydrating Cream 30 ml\n",
            "Men Raw Eau de Parfum 20 ml\n",
            "Men Classic Perfume - 100 ml\n",
            "Women Pure Musc EDP 50 ml\n",
            "Water Bottle 750 ml\n",
            "Women Eau de Parfum 100 ml\n",
            "Gentle Skin Cleanser - 125 ml\n",
            "Unisex Sustainable Face Lotion 50 ml\n",
            "Micellar Water 400 ml\n",
            "Shower Wash 200 ml\n",
            "Women Sheer EDP 20 ml\n",
            "Men Classic Blue EDT 90 ml\n",
            "Good Girl Eau de Parfum 50 ml\n",
            "Tales Malaga Perfume 100 ml\n",
            "18% HGA Hair Serum 30 ml\n",
            "Men Neo Body Spray 150 ml\n",
            "Lift & Firm Day Cream - 50 ml\n",
            "For Men Absolute EDP 100 ml\n",
            "Men Country Road EDP 100 ml\n",
            "Perfect 9 Repair Cream 60 ml\n",
            "Women Dark Desire EDP - 50 ml\n",
            "Women Celeste Deo 150 ml\n",
            "Women Fame EDP - 30 ml\n",
            "Handy 650 Water Bottle 690 ml\n",
            "Sun Protection SPF 50 Spray 100 ml\n"
          ]
        }
      ],
      "source": [
        "for i in data['name']:\n",
        "  if i.split()[-1]==\"ml\":\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp92JvGQZ105"
      },
      "source": [
        "#I am first downloading images for vernelable product detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CwtJ1s5XfCw",
        "outputId": "6b6aacb7-ce4a-4677-f562-3db1f0d1eb7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success\n",
            "fail\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n",
            "Success\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "j=0\n",
        "folder=\"images\"\n",
        "for i in data['img'][0:500]:\n",
        "  response=re.get(i)\n",
        "  if response.status_code==200:\n",
        "    file=f\"image{j}.jpg\"\n",
        "    with open(f\"{folder}/{file}\",\"wb\") as f:\n",
        "      f.write(response.content)\n",
        "    j+=1\n",
        "    print(\"Success\")\n",
        "  else:\n",
        "     print(\"fail\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV_SeeSeZyOt"
      },
      "outputs": [],
      "source": [
        "file=os.path.join(folder,\"img1.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ROTdVwgbS7y"
      },
      "outputs": [],
      "source": [
        "path=data['img'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjU_Ug56fG44"
      },
      "outputs": [],
      "source": [
        "response=re.get(path)\n",
        "with open(\"images/img1.jpg\",\"wb\") as f:\n",
        "  f.write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktJEg1A-5LP7"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Sde7DM0lvZMZ",
        "outputId": "fcc077b6-15c9-48a8-f1c2-a87f524d2a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13\n",
            "  Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.11/dist-packages (1.20.1)\n",
            "Collecting tf2onnx\n",
            "  Downloading tf2onnx-1.16.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (25.1.24)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.70.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (3.12.1)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (18.1.1)\n",
            "Collecting numpy<=1.24.3,>=1.22 (from tensorflow==2.13)\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.17.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (2.5.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow==2.13)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (1.17.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.13) (0.37.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting onnx>=1.4.1 (from tf2onnx)\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tf2onnx) (2.32.3)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.13)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.13) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (2.27.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13) (3.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tf2onnx) (2025.1.31)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13) (3.2.2)\n",
            "Downloading tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.2/524.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf2onnx-1.16.1-py3-none-any.whl (455 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m455.8/455.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: typing-extensions, tensorflow-estimator, protobuf, numpy, keras, gast, onnx, tf2onnx, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.20.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "albumentations 2.0.3 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.27.2 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "pydantic 2.10.6 requires typing-extensions>=4.12.2, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "blosc2 3.0.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "langchain-core 0.3.33 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.13.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.61.0 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "sqlalchemy 2.0.37 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 numpy-1.24.3 onnx-1.17.0 protobuf-3.20.3 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tf2onnx-1.16.1 typing-extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              },
              "id": "9a1809cfcbff45fabe886f9f9baff720"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.13 onnxruntime tf2onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgGrCjNdfcJT"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout,GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Za-j7vh-EiM",
        "outputId": "95c02632-5e99-449f-8366-7542cf253f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 978 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds=image_dataset_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/data/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=16,\n",
        "    image_size=(256,256),\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wBxXHi--evJ",
        "outputId": "d02aab5d-6bd3-4770-b901-ca49f6f48ea2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 118 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "val_ds=image_dataset_from_directory(\n",
        "    directory=\"/content/drive/MyDrive/data/test\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"int\",\n",
        "    batch_size=16,\n",
        "    image_size=(256,256),\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPRfF-bWF0U7"
      },
      "outputs": [],
      "source": [
        "def preprocess(img):\n",
        "  img=img/255.0\n",
        "  return img\n",
        "train_ds=train_ds.map(lambda x,y:(preprocess(x),y))\n",
        "val_ds=val_ds.map(lambda x,y:(preprocess(x),y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBptcJoQ8XqJ",
        "outputId": "d064110b-0951-4565-bbba-f088a7d1a00c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
            "52606240/52606240 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetV2B3\n",
        "model=EfficientNetV2B3(include_top=False,\n",
        "                       weights=\"imagenet\",\n",
        "                       input_shape=(256,256,3),\n",
        "                       classes=2,\n",
        "                       include_preprocessing=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8vVpXUm934e"
      },
      "outputs": [],
      "source": [
        "for i in model.layers:\n",
        "  i.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpeT11WW89gJ"
      },
      "outputs": [],
      "source": [
        "x=GlobalAveragePooling2D()(model.output)\n",
        "x=Dense(512,activation=\"relu\")(x)\n",
        "x=Dropout(0.2)(x)\n",
        "x=Dense(256,activation=\"relu\")(x)\n",
        "x=Dropout(0.2)(x)\n",
        "x=Dense(1,activation=\"sigmoid\")(x)\n",
        "new_model=tf.keras.models.Model(inputs=model.input,outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TTVR1Ho_I84"
      },
      "outputs": [],
      "source": [
        "new_model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Dtk_2UrA520",
        "outputId": "8633658f-04d2-4552-8231-33a074ef7457"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 145s 2s/step - loss: 0.0072 - accuracy: 0.9969 - val_loss: 0.1070 - val_accuracy: 0.9831\n"
          ]
        }
      ],
      "source": [
        "history=new_model.fit(train_ds,validation_data=val_ds,epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj8R1dchxpEp",
        "outputId": "9a61b892-b235-4a50-8840-80b420c81aa0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "new_model.save(\"vernelable_detect.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6Cf7_5K6IPI"
      },
      "outputs": [],
      "source": [
        "import tf2onnx\n",
        "import onnxruntime as rt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9JjUxvITi2I"
      },
      "outputs": [],
      "source": [
        "signature=[tf.TensorSpec([None,256,256,3],tf.float32,name=\"input\")]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model(\"/content/vernelable_detect.h5\")"
      ],
      "metadata": {
        "id": "GTxv_2Mx4dQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eY3ELwnED6-"
      },
      "outputs": [],
      "source": [
        "onnx_model,_=tf2onnx.convert.from_keras(model,signature,opset=13,output_path=\"vernelable_detect.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Ikjl7y0A1P",
        "outputId": "b4727bdd-d6a5-40cf-9baf-ffd6e95ae544"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dense_2']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "output_names=[n.name for n in onnx_model.graph.output]\n",
        "output_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NinQZ5SCy5-F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "img=Image.open(\"/content/drive/MyDrive/data/test/harmful/12Bore (1).png\")\n",
        "img=img.resize((256,256))\n",
        "img=np.array(img).astype(np.float32)/255\n",
        "img=np.expand_dims(img,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnCZmchszyxR"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort\n",
        "m=ort.InferenceSession(\"vernelable_detect.onnx\",providers=[\"CPUExecutionProvider\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.run(output_names,{\"input\":img})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0UOWwsX3CI7",
        "outputId": "bf7312e9-7e5f-4467-ffef-a8fb7efd5348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[6.175041e-05]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Q1rYqK3Mps",
        "outputId": "5c2396b0-bf97-47f8-c346-5cb9bcdbbae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.8627451 , 0.87058824, 0.8666667 ],\n",
              "        [0.8627451 , 0.87058824, 0.8666667 ],\n",
              "        [0.85882354, 0.8666667 , 0.8627451 ],\n",
              "        ...,\n",
              "        [0.3137255 , 0.3137255 , 0.29411766],\n",
              "        [0.30980393, 0.3137255 , 0.30588236],\n",
              "        [0.29803923, 0.30588236, 0.29411766]],\n",
              "\n",
              "       [[0.8745098 , 0.88235295, 0.8784314 ],\n",
              "        [0.8745098 , 0.88235295, 0.8784314 ],\n",
              "        [0.8745098 , 0.88235295, 0.8784314 ],\n",
              "        ...,\n",
              "        [0.30588236, 0.30588236, 0.28627452],\n",
              "        [0.28235295, 0.29803923, 0.28235295],\n",
              "        [0.2627451 , 0.27058825, 0.25882354]],\n",
              "\n",
              "       [[0.8862745 , 0.8980392 , 0.89411765],\n",
              "        [0.8862745 , 0.8980392 , 0.89411765],\n",
              "        [0.8862745 , 0.89411765, 0.89411765],\n",
              "        ...,\n",
              "        [0.2901961 , 0.2901961 , 0.27450982],\n",
              "        [0.2509804 , 0.27058825, 0.25882354],\n",
              "        [0.21568628, 0.22745098, 0.21568628]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.08235294, 0.07843138, 0.05882353],\n",
              "        [0.08627451, 0.08235294, 0.0627451 ],\n",
              "        [0.09019608, 0.08627451, 0.06666667],\n",
              "        ...,\n",
              "        [0.61960787, 0.6313726 , 0.62352943],\n",
              "        [0.61960787, 0.6313726 , 0.62352943],\n",
              "        [0.61960787, 0.6313726 , 0.62352943]],\n",
              "\n",
              "       [[0.07450981, 0.07058824, 0.05098039],\n",
              "        [0.07843138, 0.07450981, 0.05490196],\n",
              "        [0.09019608, 0.08627451, 0.06666667],\n",
              "        ...,\n",
              "        [0.26666668, 0.27058825, 0.26666668],\n",
              "        [0.26666668, 0.27058825, 0.26666668],\n",
              "        [0.26666668, 0.27058825, 0.26666668]],\n",
              "\n",
              "       [[0.06666667, 0.0627451 , 0.04313726],\n",
              "        [0.07058824, 0.06666667, 0.04705882],\n",
              "        [0.08627451, 0.08235294, 0.0627451 ],\n",
              "        ...,\n",
              "        [0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VAds58VE5YSM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17ycQUxtYWivDfc1RMSCovuuku5iP7XxT",
      "authorship_tag": "ABX9TyMWGIVgMVqusVWLpkbdCWPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}